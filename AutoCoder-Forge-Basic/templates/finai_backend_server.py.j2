project 1\AutoCoder-Forge-Basic\templates\finai_backend_server.py.j2
"""
FinAI Hub Backend Server
Generated by AutoCoder

Template variables:
  - host: str (server host)
  - port: int (server port)
  - kronos_model: str (Kronos model path)
  - docsgpt_url: str (DocsGPT API URL)
  - goose_url: str (Goose MCP URL)
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import uvicorn
import requests
import json
import pandas as pd
from datetime import datetime
import torch

# Import integrated tools
try:
    from model import Kronos, KronosTokenizer, KronosPredictor
    KRONOS_AVAILABLE = True
except ImportError:
    KRONOS_AVAILABLE = False

app = FastAPI(
    title="FinAI Hub Backend API",
    description="Backend API for FinAI Hub financial analytics platform",
    version="1.0.0"
)

# CORS middleware for Streamlit frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global instances
kronos_predictor = None
docsgpt_url = "{{ docsgpt_url }}"
goose_url = "{{ goose_url }}"

# Pydantic models
class KronosPredictionRequest(BaseModel):
    historical_data: List[Dict[str, Any]]
    prediction_length: int = 120
    temperature: float = 1.0
    top_p: float = 0.9
    sample_count: int = 1

class KronosPredictionResponse(BaseModel):
    predictions: List[Dict[str, Any]]
    metadata: Dict[str, Any]

class DocumentQueryRequest(BaseModel):
    question: str
    document_id: Optional[str] = None

class DocumentQueryResponse(BaseModel):
    answer: str
    sources: List[Dict[str, Any]]
    confidence: float

class AutomationRequest(BaseModel):
    action: str
    parameters: Dict[str, Any] = {}

class AutomationResponse(BaseModel):
    result: Dict[str, Any]
    status: str

class LadderProgressRequest(BaseModel):
    user_id: str

class LadderProgressResponse(BaseModel):
    user_id: str
    current_level: int
    next_level_requirements: Dict[str, Any]
    progress: float

class SocialFeedResponse(BaseModel):
    user_id: str
    posts: List[Dict[str, Any]]

@app.on_event("startup")
async def startup_event():
    """Initialize models and services on startup"""
    global kronos_predictor

    if KRONOS_AVAILABLE:
        try:
            tokenizer = KronosTokenizer.from_pretrained("NeoQuasar/Kronos-Tokenizer-base")
            model = Kronos.from_pretrained("{{ kronos_model }}")
            kronos_predictor = KronosPredictor(
                model, tokenizer,
                device="cuda:0" if torch.cuda.is_available() else "cpu"
            )
            print("Kronos predictor initialized")
        except Exception as e:
            print(f"Failed to initialize Kronos: {e}")
    else:
        print("Kronos not available")

@app.get("/")
async def root():
    return {"message": "FinAI Hub Backend API", "status": "running"}

@app.get("/health")
async def health_check():
    services_status = {
        "kronos": KRONOS_AVAILABLE and kronos_predictor is not None,
        "docsgpt": check_service_health(docsgpt_url),
        "goose": check_service_health(goose_url)
    }

    return {
        "status": "healthy" if all(services_status.values()) else "degraded",
        "services": services_status,
        "timestamp": datetime.utcnow().isoformat()
    }

def check_service_health(url: str) -> bool:
    """Check if a service is healthy"""
    try:
        response = requests.get(f"{url}/status", timeout=5)
        return response.status_code == 200
    except:
        return False

# Kronos API endpoints
@app.post("/api/v1/kronos/predict", response_model=KronosPredictionResponse)
async def predict_market(request: KronosPredictionRequest):
    if not kronos_predictor:
        raise HTTPException(status_code=503, detail="Kronos predictor not available")

    try:
        # Convert historical data to DataFrame
        df = pd.DataFrame(request.historical_data)
        required_cols = ['open', 'high', 'low', 'close']
        if not all(col in df.columns for col in required_cols):
            raise HTTPException(status_code=400, detail="Missing required columns")

        # Prepare timestamps
        lookback = len(df)
        x_timestamp = pd.to_datetime(df.index) if df.index.name != 'date' else pd.to_datetime(df.index)
        pred_len = request.prediction_length
        y_timestamp = pd.date_range(start=x_timestamp.iloc[-1], periods=pred_len+1, freq='D')[1:]

        # Generate prediction
        pred_df = kronos_predictor.predict(
            df=df,
            x_timestamp=x_timestamp,
            y_timestamp=y_timestamp,
            pred_len=pred_len,
            T=request.temperature,
            top_p=request.top_p,
            sample_count=request.sample_count
        )

        predictions = pred_df.to_dict('records')
        metadata = {
            "lookback": lookback,
            "prediction_length": pred_len,
            "model": "{{ kronos_model }}",
            "generated_at": datetime.utcnow().isoformat()
        }

        return KronosPredictionResponse(predictions=predictions, metadata=metadata)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")

@app.get("/api/v1/kronos/status")
async def kronos_status():
    return {
        "available": kronos_predictor is not None,
        "model": "{{ kronos_model }}" if kronos_predictor else None
    }

# DocsGPT API endpoints
@app.post("/api/v1/docsgpt/query", response_model=DocumentQueryResponse)
async def query_documents(request: DocumentQueryRequest):
    try:
        payload = {"question": request.question}
        if request.document_id:
            payload["document_id"] = request.document_id

        response = requests.post(f"{docsgpt_url}/api/answer", json=payload, timeout=30)
        response.raise_for_status()

        data = response.json()

        return DocumentQueryResponse(
            answer=data.get("answer", "No answer available"),
            sources=data.get("sources", []),
            confidence=data.get("confidence", 0.5)
        )

    except requests.RequestException as e:
        raise HTTPException(status_code=503, detail=f"DocsGPT unavailable: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Query failed: {str(e)}")

@app.get("/api/v1/docsgpt/documents")
async def list_documents():
    try:
        response = requests.get(f"{docsgpt_url}/api/documents", timeout=10)
        response.raise_for_status()
        return response.json()
    except requests.RequestException as e:
        raise HTTPException(status_code=503, detail=f"DocsGPT unavailable: {str(e)}")

@app.get("/api/v1/docsgpt/status")
async def docsgpt_status():
    return {"available": check_service_health(docsgpt_url)}

# Goose API endpoints
@app.post("/api/v1/goose/automate", response_model=AutomationResponse)
async def run_automation(request: AutomationRequest):
    try:
        payload = {
            "action": request.action,
            "parameters": request.parameters
        }
        response = requests.post(f"{goose_url}/automate", json=payload, timeout=30)
        response.raise_for_status()

        data = response.json()
        return AutomationResponse(result=data, status="success")

    except requests.RequestException as e:
        raise HTTPException(status_code=503, detail=f"Goose MCP unavailable: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Automation failed: {str(e)}")

@app.get("/api/v1/goose/status")
async def goose_status():
    return {"available": check_service_health(goose_url)}

# Laddr API endpoints
@app.post("/api/v1/laddr/progress", response_model=LadderProgressResponse)
async def get_ladder_progress(request: LadderProgressRequest):
    # Simplified ladder logic - in real implementation, this would query a database
    try:
        # Mock user progress data
        user_progress = {
            "john_investor": {"level": 3, "progress": 0.75},
            "demo_user": {"level": 2, "progress": 0.65}
        }

        progress_data = user_progress.get(request.user_id, {"level": 1, "progress": 0.0})
        current_level = progress_data["level"]
        progress = progress_data["progress"]

        # Calculate next level requirements
        next_level_reqs = {
            "investments_needed": 5 - (current_level * 2),
            "minimum_portfolio_value": 10000 * current_level
        }

        return LadderProgressResponse(
            user_id=request.user_id,
            current_level=current_level,
            next_level_requirements=next_level_reqs,
            progress=progress
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Ladder calculation failed: {str(e)}")

@app.get("/api/v1/laddr/levels")
async def get_ladder_levels():
    return {
        "levels": [
            {"level": 1, "name": "Beginner Investor", "requirements": "Open account"},
            {"level": 2, "name": "Active Trader", "requirements": "10 trades"},
            {"level": 3, "name": "Portfolio Builder", "requirements": "$25k portfolio"},
            {"level": 4, "name": "Expert Investor", "requirements": "Consistent returns"},
            {"level": 5, "name": "Master Investor", "requirements": "Mentor others"}
        ]
    }

@app.get("/api/v1/laddr/status")
async def laddr_status():
    return {"available": True, "service": "Laddr Ladder"}

# Vutuv API endpoints
@app.get("/api/v1/vutuv/feed/{user_id}", response_model=SocialFeedResponse)
async def get_social_feed(user_id: str):
    # Mock social feed data
    mock_posts = [
        {
            "post_id": "post_1",
            "user": "Sarah Trader",
            "content": "Bullish on tech stocks for Q4!",
            "likes": 15,
            "timestamp": datetime.utcnow().isoformat()
        },
        {
            "post_id": "post_2",
            "user": "Mike Analyst",
            "content": "Market analysis: Expect volatility next week",
            "likes": 8,
            "timestamp": datetime.utcnow().isoformat()
        },
        {
            "post_id": "post_3",
            "user": "Crypto King",
            "content": "Bitcoin showing strong support at $60k",
            "likes": 23,
            "timestamp": datetime.utcnow().isoformat()
        }
    ]

    return SocialFeedResponse(user_id=user_id, posts=mock_posts)

@app.post("/api/v1/vutuv/post")
async def create_post(post_data: Dict[str, Any]):
    # Mock post creation
    return {
        "post_id": f"post_{post_data.get('user_id', 'anon')}_{len(post_data.get('content', ''))}",
        "status": "posted",
        "timestamp": datetime.utcnow().isoformat()
    }

@app.get("/api/v1/vutuv/status")
async def vutuv_status():
    return {"available": True, "service": "Vutuv Social"}

if __name__ == "__main__":
    uvicorn.run(
        "finai_backend_server:app",
        host="{{ host }}",
        port={{ port }},
        reload=True
    )
